{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Изображение](images.jpeg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N_1LrIQjL-7"
      },
      "source": [
        "- Analyst Agent (решает: нужна команда)\n",
        "- Command Agent (генерирует код)\n",
        "- Colab Runtime (исполняет)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3HkBKUElTop"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip -q install -qU langchain==0.3.27 langchain-mistralai==0.2.12 python-dotenv==1.1.1 langgraph==0.2.19 mistralai faiss-cpu==1.13.2 sentence-transformers==5.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKa14FgJiaLQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "MISTRAL_API_KEY = userdata.get(\"MISTRAL_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAxA1lAJnQhw"
      },
      "source": [
        "Настройка mistral<br>\n",
        "Изменения в новой версии https://github.com/mistralai/client-python/blob/main/MIGRATION.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfiTSKT4hFin"
      },
      "outputs": [],
      "source": [
        "from mistralai.client import MistralClient\n",
        "from mistralai import Mistral, UserMessage, SystemMessage\n",
        "import uuid\n",
        "import json\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "client = Mistral(api_key=MISTRAL_API_KEY)\n",
        "\n",
        "def mistral_chat(system, user):\n",
        "    resp = client.chat.complete(\n",
        "        model=\"mistral-large-latest\",\n",
        "        messages=[\n",
        "            SystemMessage(role=\"system\", content=system),\n",
        "            UserMessage(role=\"user\", content=user)\n",
        "        ]\n",
        "    )\n",
        "    return resp.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrKYDqSJGRb8"
      },
      "outputs": [],
      "source": [
        "class MemoryAgent:\n",
        "    def __init__(self, dim=384):\n",
        "        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "        self.index = faiss.IndexFlatL2(dim)\n",
        "        self.store = {}\n",
        "\n",
        "    def add(self, text: str):\n",
        "        emb = self.model.encode([text])\n",
        "        self.index.add(emb)\n",
        "        self.store[self.index.ntotal - 1] = text\n",
        "\n",
        "    def search(self, query: str, k=3):\n",
        "        if self.index.ntotal == 0:\n",
        "            return []\n",
        "        q_emb = self.model.encode([query])\n",
        "        _, idx = self.index.search(q_emb, k)\n",
        "        return [self.store[i] for i in idx[0] if i in self.store]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ok4nRJmZGTNi"
      },
      "outputs": [],
      "source": [
        "class RetrieverAgent:\n",
        "    def __init__(self, docs):\n",
        "        self.docs = docs\n",
        "        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "        emb = self.model.encode(docs)\n",
        "\n",
        "        self.index = faiss.IndexFlatL2(emb.shape[1])\n",
        "        self.index.add(emb)\n",
        "\n",
        "    def search(self, query, k=3):\n",
        "        q_emb = self.model.encode([query])\n",
        "        _, idx = self.index.search(q_emb, k)\n",
        "        return [self.docs[i] for i in idx[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIFrR-SdGTaS"
      },
      "outputs": [],
      "source": [
        "class ColabExecutor:\n",
        "    def run(self, code: str):\n",
        "        try:\n",
        "            local_env = {}\n",
        "            exec(code, {}, local_env)\n",
        "            return {\n",
        "                \"status\": \"success\",\n",
        "                \"output\": str(local_env)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"status\": \"error\",\n",
        "                \"traceback\": str(e)\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WeSPjmzGTm3"
      },
      "outputs": [],
      "source": [
        "def command_agent(task: str, memory: MemoryAgent, executor: ColabExecutor):\n",
        "    # 1. генерация кода\n",
        "    code = client.chat.complete(\n",
        "        model=\"mistral-large-latest\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Сгенерируй Python-код. Только код.\"},\n",
        "            {\"role\": \"user\", \"content\": task}\n",
        "        ]\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    # 2. выполнение\n",
        "    result = executor.run(code)\n",
        "\n",
        "    # 3. автодебаг\n",
        "    retries = 2\n",
        "    while result[\"status\"] == \"error\" and retries > 0:\n",
        "        code = client.chat.complete(\n",
        "            model=\"mistral-large-latest\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Исправь ошибку и верни только код.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"Код:\\n{code}\\nОшибка:\\n{result['traceback']}\"}\n",
        "            ]\n",
        "        ).choices[0].message.content\n",
        "\n",
        "        result = executor.run(code)\n",
        "        retries -= 1\n",
        "\n",
        "    # 4. ревью\n",
        "    review = client.chat.complete(\n",
        "        model=\"mistral-large-latest\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Сделай краткое техническое ревью.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Код:\\n{code}\\nРезультат:\\n{result}\"}\n",
        "        ]\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    memory.add(f\"Task: {task}\\nCode:\\n{code}\\nResult:\\n{result}\")\n",
        "\n",
        "    return f\"{result}\\n\\nREVIEW:\\n{review}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJgTm348GTzO"
      },
      "outputs": [],
      "source": [
        "functions = [\n",
        "    {\n",
        "        \"name\": \"search_docs\",\n",
        "        \"description\": \"Поиск по документации\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"query\": {\"type\": \"string\"}\n",
        "            },\n",
        "            \"required\": [\"query\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"run_code\",\n",
        "        \"description\": \"Сгенерировать и выполнить код\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"task\": {\"type\": \"string\"}\n",
        "            },\n",
        "            \"required\": [\"task\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"final_answer\",\n",
        "        \"description\": \"Финальный ответ пользователю\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"answer\": {\"type\": \"string\"}\n",
        "            },\n",
        "            \"required\": [\"answer\"]\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0LjguTTHQ7y"
      },
      "outputs": [],
      "source": [
        "def dispatch(name, args, retriever, memory, executor):\n",
        "    if name == \"search_docs\":\n",
        "        return \"\\n\".join(retriever.search(args[\"query\"]))\n",
        "\n",
        "    if name == \"run_code\":\n",
        "        return command_agent(args[\"task\"], memory, executor)\n",
        "\n",
        "    if name == \"final_answer\":\n",
        "        return args[\"answer\"]\n",
        "\n",
        "    raise ValueError(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ4oOweHHUhY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def jarvis_loop(user_input, retriever, memory, executor):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": (\n",
        "            \"Ты JARVIS — AI ассистент программиста.\\n\"\n",
        "            \"Если нужно выполнить задачу, ответь строго в JSON формате:\\n\"\n",
        "            '{\"action\": \"run_code\"|\"search_docs\"|\"final_answer\", \"args\": {...}}'\n",
        "        )},\n",
        "        {\"role\": \"user\", \"content\": user_input}\n",
        "    ]\n",
        "\n",
        "    while True:\n",
        "        response = client.chat.complete(\n",
        "            model=\"mistral-large-latest\",\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        msg_text = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Пытаемся разобрать JSON\n",
        "        try:\n",
        "            msg_json = json.loads(msg_text)\n",
        "            action = msg_json.get(\"action\")\n",
        "            args = msg_json.get(\"args\", {})\n",
        "        except Exception:\n",
        "            # Если LLM не вернул JSON, выдаём как финальный ответ\n",
        "            memory.add(f\"USER: {user_input}\\nASSISTANT: {msg_text}\")\n",
        "            return msg_text\n",
        "\n",
        "        # Диспетчер\n",
        "        result = dispatch(action, args, retriever, memory, executor)\n",
        "\n",
        "        # добавляем результат в контекст для следующего шага\n",
        "        messages.append({\"role\": \"assistant\", \"content\": msg_text})\n",
        "        messages.append({\"role\": \"function\", \"name\": action, \"content\": str(result)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pgbcu6NHuyV"
      },
      "outputs": [],
      "source": [
        "docs = [\n",
        "    \"RandomForest — ансамблевый метод машинного обучения.\",\n",
        "    \"Accuracy — доля правильных ответов.\",\n",
        "    \"FAISS используется для векторного поиска.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKsDpb19HvFq",
        "outputId": "fce2d2fc-dc8c-4d4e-fdb7-393b580c4736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "  \"action\": \"run_code\",\n",
            "  \"args\": {\n",
            "    \"code\": \"from sklearn.datasets import load_iris\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import accuracy_score\\n\\n# Загрузка данных\\niris = load_iris()\\nX, y = iris.data, iris.target\\n\\n# Разделение на обучающую и тестовую выборки\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Обучение модели\\nmodel = RandomForestClassifier(random_state=42)\\nmodel.fit(X_train, y_train)\\n\\n# Предсказание и расчет accuracy\\ny_pred = model.predict(X_test)\\naccuracy = accuracy_score(y_test, y_pred)\\n\\n# Вывод результата\\nprint(f\\\"Accuracy: {accuracy:.4f}\\\")\",\n",
            "    \"description\": \"Обучение RandomForest на датасете iris и вывод accuracy.\"\n",
            "  }\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "retriever = RetrieverAgent(docs)\n",
        "memory = MemoryAgent()\n",
        "executor = ColabExecutor()\n",
        "\n",
        "answer = jarvis_loop(\n",
        "    \"Обучи RandomForest на iris и выведи accuracy\",\n",
        "    retriever,\n",
        "    memory,\n",
        "    executor\n",
        ")\n",
        "\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rntngyPiHvVY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klrQmvWOHvi2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
